# Plan: Remove Legacy Format Support from generate_audio.py

## Summary

Remove all legacy format support from `generate_audio.py`. Keep only the new format as shown in `examples/sample-audio-script.md`.

## New Format (to keep)

```yaml
---
stageUuid: "stage-entering-forest"
chapterRef: "02-entering-forest"
locale: "en-US"
speakers:
  - name: Narrator
    voice: Sulafat
    profile: "Warm storyteller..."
  - name: Emma
    voice: Leda
    profile: "8-year-old girl..."
---

**Narrator:** <emotion: warm, inviting> Text here...
**Emma:** <emotion: curious> More text...
```

## Legacy Format (to remove)

The legacy format had:
- `speakers: ["Narrator", "Emma"]` (list of strings instead of objects)
- `## TTS CONFIGURATION` section with JSON block
- `## TRANSCRIPT` section
- `# AUDIO PROFILE`, `## THE SCENE`, `### DIRECTOR'S NOTES` sections

## Changes Required

### File: `generate_audio.py`

1. **Remove legacy constants** (lines 62-64):
   ```python
   # Legacy chunking constants (for backward compatibility)
   MAX_CHUNK_SIZE = 6000
   CHUNK_PAUSE_MS = 300
   ```

2. **Simplify AudioScript dataclass** (lines 145-148) - remove legacy fields:
   ```python
   transcript: str = ""  # Raw transcript (for legacy format detection)
   style_context: str = ""  # Scene + Director's notes (legacy)
   ```

3. **Remove `is_new_format()` function** (lines 301-324)

4. **Remove `_parse_legacy_format()` function** (lines 439-523)

5. **Simplify `parse_audio_script()`** (lines 332-395):
   - Remove format detection logic
   - Remove call to `_parse_legacy_format()`
   - Directly parse the new format
   - Update docstring to remove legacy format documentation

6. **Remove unused `json` import** (line 28) - only used by legacy parser

## Files to Modify

- `/Users/yannick.grenzinger/Work/code/playground/ai-studio-story/generate_audio.py`

## Verification

1. **Run with new format example:**
   ```bash
   .venv/bin/python generate_audio.py examples/sample-audio-script.md -o /tmp/test.mp3 --debug --no-progress
   ```

2. **Verify parsing works correctly:**
   - Speakers parsed from frontmatter with voice and profile
   - Segments parsed with emotion markers
   - Audio generation completes successfully
